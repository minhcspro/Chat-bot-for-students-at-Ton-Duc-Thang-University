{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6b5ac8",
   "metadata": {
    "id": "N10v8EqGI1Ro",
    "papermill": {
     "duration": 0.027134,
     "end_time": "2022-05-29T15:54:47.606538",
     "exception": false,
     "start_time": "2022-05-29T15:54:47.579404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Xây dựng Chatbot sử dụng mô hình Sequence2Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e73d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:54:47.660077Z",
     "iopub.status.busy": "2022-05-29T15:54:47.659694Z",
     "iopub.status.idle": "2022-05-29T15:55:01.914322Z",
     "shell.execute_reply": "2022-05-29T15:55:01.913557Z"
    },
    "id": "s16yZMa6JCQt",
    "outputId": "856d1524-bf72-4027-d04b-465b0b425be8",
    "papermill": {
     "duration": 14.284114,
     "end_time": "2022-05-29T15:55:01.916485",
     "exception": false,
     "start_time": "2022-05-29T15:54:47.632371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting underthesea\r\n",
      "  Downloading underthesea-1.3.4-py3-none-any.whl (7.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from underthesea) (2.27.1)\r\n",
      "Collecting python-crfsuite>=0.9.6\r\n",
      "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.2)\r\n",
      "Collecting underthesea-core==0.0.4_alpha.10\r\n",
      "  Downloading underthesea_core-0.0.4_alpha.10-cp37-cp37m-manylinux2010_x86_64.whl (581 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.2/581.2 KB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from underthesea) (6.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from underthesea) (3.2.4)\r\n",
      "Requirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from underthesea) (8.0.4)\r\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.3.4)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from underthesea) (4.63.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=6.0->underthesea) (4.11.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->underthesea) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (1.26.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2021.10.8)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2.0.12)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (3.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.21.6)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.7.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.2.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.7.0)\r\n",
      "Installing collected packages: underthesea-core, python-crfsuite, underthesea\r\n",
      "Successfully installed python-crfsuite-0.9.8 underthesea-1.3.4 underthesea-core-0.0.4a10\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44901c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:01.998483Z",
     "iopub.status.busy": "2022-05-29T15:55:01.998221Z",
     "iopub.status.idle": "2022-05-29T15:55:08.229194Z",
     "shell.execute_reply": "2022-05-29T15:55:08.228477Z"
    },
    "id": "BECuUXItI1o5",
    "papermill": {
     "duration": 6.273928,
     "end_time": "2022-05-29T15:55:08.231328",
     "exception": false,
     "start_time": "2022-05-29T15:55:01.957400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,string\n",
    "from gensim.models import KeyedVectors\n",
    "from collections import Counter\n",
    "from underthesea import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import utils\n",
    "from tensorflow.keras import preprocessing, utils, activations\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cbfdde6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:08.314302Z",
     "iopub.status.busy": "2022-05-29T15:55:08.314085Z",
     "iopub.status.idle": "2022-05-29T15:55:08.353987Z",
     "shell.execute_reply": "2022-05-29T15:55:08.353267Z"
    },
    "id": "_Va-SWVOJLeO",
    "outputId": "11990d37-cb42-4ab3-9a42-368d8fe76c1e",
    "papermill": {
     "duration": 0.082146,
     "end_time": "2022-05-29T15:55:08.356041",
     "exception": false,
     "start_time": "2022-05-29T15:55:08.273895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_a</th>\n",
       "      <th>user_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Thích mẫu người nào</td>\n",
       "      <td>Dễ thương, tóc dài, da trắng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Có crush ai không</td>\n",
       "      <td>Có 1 bạn cùng lớp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tại sao lại thích bạn dó</td>\n",
       "      <td>Vì đáp ứng những yêu cầu của tao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Có hay nói chuyện không</td>\n",
       "      <td>Hay nhắn tin messenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bạn kia có bắt chuyện trước không</td>\n",
       "      <td>Có đôi khi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             user_a  \\\n",
       "0           0                Thích mẫu người nào   \n",
       "1           1                  Có crush ai không   \n",
       "2           2           Tại sao lại thích bạn dó   \n",
       "3           3            Có hay nói chuyện không   \n",
       "4           4  Bạn kia có bắt chuyện trước không   \n",
       "\n",
       "                             user_b  \n",
       "0      Dễ thương, tóc dài, da trắng  \n",
       "1                 Có 1 bạn cùng lớp  \n",
       "2  Vì đáp ứng những yêu cầu của tao  \n",
       "3            Hay nhắn tin messenger  \n",
       "4                        Có đôi khi  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/vietnamese-chatbot/d liu chatbot question-answer short style.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7252b81c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:08.437199Z",
     "iopub.status.busy": "2022-05-29T15:55:08.436975Z",
     "iopub.status.idle": "2022-05-29T15:55:08.441524Z",
     "shell.execute_reply": "2022-05-29T15:55:08.440885Z"
    },
    "id": "7pSEtATtj5VL",
    "outputId": "c94199ba-d188-4511-c8a0-ae263bae257c",
    "papermill": {
     "duration": 0.04715,
     "end_time": "2022-05-29T15:55:08.443194",
     "exception": false,
     "start_time": "2022-05-29T15:55:08.396044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5900, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f35c87",
   "metadata": {
    "id": "WHl7tRh9lO9n",
    "papermill": {
     "duration": 0.039332,
     "end_time": "2022-05-29T15:55:08.522934",
     "exception": false,
     "start_time": "2022-05-29T15:55:08.483602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Text Cleaning / Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe256c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:08.603755Z",
     "iopub.status.busy": "2022-05-29T15:55:08.603543Z",
     "iopub.status.idle": "2022-05-29T15:55:08.611261Z",
     "shell.execute_reply": "2022-05-29T15:55:08.610639Z"
    },
    "id": "UkcfrZNKlm9i",
    "outputId": "66d7ca6f-fe52-4c7d-d8a8-775723065e2b",
    "papermill": {
     "duration": 0.050303,
     "end_time": "2022-05-29T15:55:08.612956",
     "exception": false,
     "start_time": "2022-05-29T15:55:08.562653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "user_a        0\n",
       "user_b        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6477b02e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:08.695001Z",
     "iopub.status.busy": "2022-05-29T15:55:08.694781Z",
     "iopub.status.idle": "2022-05-29T15:55:08.705350Z",
     "shell.execute_reply": "2022-05-29T15:55:08.704686Z"
    },
    "id": "6rEQUmGqhPJY",
    "outputId": "8c8c6859-d9e3-4772-b59b-6448e1ab5403",
    "papermill": {
     "duration": 0.053616,
     "end_time": "2022-05-29T15:55:08.707408",
     "exception": false,
     "start_time": "2022-05-29T15:55:08.653792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question of nan answer:  ['Anh chị em làm gì?']\n"
     ]
    }
   ],
   "source": [
    "idx = df[df['user_b'].isnull()].index.tolist() # Get index of nan row\n",
    "print('Question of nan answer: ' ,df['user_a'][idx].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acef5509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:08.790817Z",
     "iopub.status.busy": "2022-05-29T15:55:08.790591Z",
     "iopub.status.idle": "2022-05-29T15:55:08.795485Z",
     "shell.execute_reply": "2022-05-29T15:55:08.794791Z"
    },
    "id": "shyshZ51lsWG",
    "papermill": {
     "duration": 0.047941,
     "end_time": "2022-05-29T15:55:08.797174",
     "exception": false,
     "start_time": "2022-05-29T15:55:08.749233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill in nan row value\n",
    "df['user_b'] = df['user_b'].fillna('Luật sư').values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c6193f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:08.879590Z",
     "iopub.status.busy": "2022-05-29T15:55:08.879354Z",
     "iopub.status.idle": "2022-05-29T15:55:08.997858Z",
     "shell.execute_reply": "2022-05-29T15:55:08.997147Z"
    },
    "id": "hYVnIqkEJTTj",
    "papermill": {
     "duration": 0.162083,
     "end_time": "2022-05-29T15:55:08.999902",
     "exception": false,
     "start_time": "2022-05-29T15:55:08.837819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "EMOTICONS = { \n",
    "    u\":-3\":\"Happy face smiley\",\n",
    "    u\":3\":\"Happy face smiley\",\n",
    "    u\":->\":\"Happy face smiley\",\n",
    "    u\":>\":\"Happy face smiley\",\n",
    "    u\":))\":\"Happy face smiley\",\n",
    "    u\":)))\":\"Happy face smiley\",\n",
    "    u\":))))\":\"Happy face smiley\",\n",
    "    u\":'<\":\"Happy face smiley\",\n",
    "    u\":)\":\"Happy face smiley\",\n",
    "    u\":(\":\"Happy face smiley\",\n",
    "    u\":((\":\"Happy face smiley\",\n",
    "    u\":‑D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":‑c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":‑<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":@\":\"Frown, sad, andry or pouting\",\n",
    "    u\"D:\":\"Sadness\",\n",
    "    u\":O\":\"Surprise\",\n",
    "    u\":o\":\"Surprise\",\n",
    "}\n",
    "\n",
    "cnt = Counter()\n",
    "for text in df[\"user_b\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-10-1:-1]]) #Get top 10 rare word\n",
    "\n",
    "def remove_emoticons(text):\n",
    "    \"Function to remove emoticons\"\n",
    "    arr = [word for word in text.split() if word not in EMOTICONS.keys()]\n",
    "    return \" \".join(arr)\n",
    "\n",
    "def remove_rarewords(text):\n",
    "    \"\"\"custom function to remove the rare words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
    "\n",
    "def preprocessing(df): \n",
    "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation))) # Remove punctuation\n",
    "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation))) \n",
    "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: remove_emoticons(ele)) # Remove emoticons\n",
    "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: remove_emoticons(ele))\n",
    "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: remove_rarewords(ele)) # Remove rarewords\n",
    "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: remove_rarewords(ele))\n",
    "  df['user_b'] = df['user_b'].apply(lambda ele: 'START ' + ele + ' END')\n",
    "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: ele.lower()) # convert text to lowercase\n",
    "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: ele.lower()) \n",
    "  \n",
    "  return df\n",
    "\n",
    "df = preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e427f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:09.083427Z",
     "iopub.status.busy": "2022-05-29T15:55:09.083189Z",
     "iopub.status.idle": "2022-05-29T15:55:09.089219Z",
     "shell.execute_reply": "2022-05-29T15:55:09.088546Z"
    },
    "id": "hHcACgVuJWQf",
    "outputId": "e5197964-a274-4f27-de7c-9eab6670aa9d",
    "papermill": {
     "duration": 0.049909,
     "end_time": "2022-05-29T15:55:09.091183",
     "exception": false,
     "start_time": "2022-05-29T15:55:09.041274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thích mẫu người nào' 'có crush ai không' 'tại sao lại thích bạn dó'\n",
      " 'có hay nói chuyện không' 'bạn kia có bắt chuyện trước không']\n",
      "['start dễ thương tóc dài da trắng end' 'start có 1 bạn cùng lớp end'\n",
      " 'start vì đáp ứng những yêu cầu của tao end'\n",
      " 'start hay nhắn tin messenger end' 'start có đôi khi end']\n"
     ]
    }
   ],
   "source": [
    "data = df.values #numpy \n",
    "questions = data[:,1] # convert question to a list\n",
    "answers = data[:,2] # convert answer that match with question to list\n",
    "print(questions[:5]) \n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c96856",
   "metadata": {
    "papermill": {
     "duration": 0.041452,
     "end_time": "2022-05-29T15:55:09.173476",
     "exception": false,
     "start_time": "2022-05-29T15:55:09.132024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Tokenization and Encode, Decode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37250956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:09.256827Z",
     "iopub.status.busy": "2022-05-29T15:55:09.256576Z",
     "iopub.status.idle": "2022-05-29T15:55:10.588946Z",
     "shell.execute_reply": "2022-05-29T15:55:10.587310Z"
    },
    "id": "tM0OEAcmJZZY",
    "outputId": "f92e1958-5c12-4f8d-e8f3-94b50715760b",
    "papermill": {
     "duration": 1.376928,
     "end_time": "2022-05-29T15:55:10.591238",
     "exception": false,
     "start_time": "2022-05-29T15:55:09.214310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900\n",
      "[['thích', 'mẫu', 'người', 'nào'], ['có', 'crush', 'ai', 'không'], ['tại sao', 'lại', 'thích', 'bạn', 'dó']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization questions\n",
    "questions = [word_tokenize(ques) for ques in questions]\n",
    "print(len(questions))\n",
    "print(questions[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fae10c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:10.676574Z",
     "iopub.status.busy": "2022-05-29T15:55:10.676337Z",
     "iopub.status.idle": "2022-05-29T15:55:12.046447Z",
     "shell.execute_reply": "2022-05-29T15:55:12.045683Z"
    },
    "id": "axGM_AzyKMP-",
    "outputId": "be31a17c-da33-4ceb-e5d0-b174c8e45272",
    "papermill": {
     "duration": 1.416132,
     "end_time": "2022-05-29T15:55:12.049580",
     "exception": false,
     "start_time": "2022-05-29T15:55:10.633448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900\n",
      "[['start', 'dễ thương', 'tóc', 'dài', 'da', 'trắng', 'end'], ['start', 'có', '1', 'bạn', 'cùng', 'lớp', 'end'], ['start', 'vì', 'đáp ứng', 'những', 'yêu cầu', 'của', 'tao', 'end']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization answer\n",
    "answers = [word_tokenize(ans) for ans in answers]\n",
    "print(len(answers))\n",
    "print(answers[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4179caf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:12.137720Z",
     "iopub.status.busy": "2022-05-29T15:55:12.137480Z",
     "iopub.status.idle": "2022-05-29T15:55:12.206759Z",
     "shell.execute_reply": "2022-05-29T15:55:12.205921Z"
    },
    "id": "QsR71gvjKC1-",
    "outputId": "c310b7db-031a-4bde-8aa7-c17160231259",
    "papermill": {
     "duration": 0.114362,
     "end_time": "2022-05-29T15:55:12.209466",
     "exception": false,
     "start_time": "2022-05-29T15:55:12.095104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 3644\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ef446ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:12.296983Z",
     "iopub.status.busy": "2022-05-29T15:55:12.296318Z",
     "iopub.status.idle": "2022-05-29T15:55:12.300763Z",
     "shell.execute_reply": "2022-05-29T15:55:12.300090Z"
    },
    "id": "xRrlh0_NLe5g",
    "outputId": "96136cf9-b50d-4b33-de58-6f4ee828a09c",
    "papermill": {
     "duration": 0.049468,
     "end_time": "2022-05-29T15:55:12.302638",
     "exception": false,
     "start_time": "2022-05-29T15:55:12.253170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word2idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc868e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:12.388036Z",
     "iopub.status.busy": "2022-05-29T15:55:12.387540Z",
     "iopub.status.idle": "2022-05-29T15:55:12.435427Z",
     "shell.execute_reply": "2022-05-29T15:55:12.434241Z"
    },
    "id": "LRbibHDuKqY0",
    "outputId": "41a49e62-c8f8-4be8-ce03-857836309b14",
    "papermill": {
     "duration": 0.093721,
     "end_time": "2022-05-29T15:55:12.437857",
     "exception": false,
     "start_time": "2022-05-29T15:55:12.344136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length question: 76\n",
      "(5900, 76)\n"
     ]
    }
   ],
   "source": [
    "#encoder_input_data\n",
    "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
    "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
    "padded_questions = pad_sequences(tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "print(\"Max length question:\", maxlen_questions)\n",
    "print(encoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9687ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:12.524073Z",
     "iopub.status.busy": "2022-05-29T15:55:12.523511Z",
     "iopub.status.idle": "2022-05-29T15:55:12.571029Z",
     "shell.execute_reply": "2022-05-29T15:55:12.569851Z"
    },
    "id": "FSuEOE4rLCzo",
    "outputId": "f82dabc2-6649-4901-a519-2fd974f86576",
    "papermill": {
     "duration": 0.092614,
     "end_time": "2022-05-29T15:55:12.573338",
     "exception": false,
     "start_time": "2022-05-29T15:55:12.480724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length anwser: 43\n",
      "(5900, 43)\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding='post')\n",
    "decoder_input_data = np.array(padded_answers)\n",
    "print(\"Max length anwser:\", maxlen_answers)\n",
    "print(decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a300c6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:12.660919Z",
     "iopub.status.busy": "2022-05-29T15:55:12.660160Z",
     "iopub.status.idle": "2022-05-29T15:55:15.227264Z",
     "shell.execute_reply": "2022-05-29T15:55:15.225619Z"
    },
    "id": "AEHXML0aLRx9",
    "outputId": "e52b5621-ed3c-4e65-8ab2-3c761d452a88",
    "papermill": {
     "duration": 2.612295,
     "end_time": "2022-05-29T15:55:15.229033",
     "exception": false,
     "start_time": "2022-05-29T15:55:12.616738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5900, 43, 3644)\n"
     ]
    }
   ],
   "source": [
    "# decoder_output_data\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "# Remove Start added before\n",
    "for i in range(len(tokenized_answers)):\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding='post')\n",
    "onehot_answers = utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
    "decoder_output_data = np.array(onehot_answers)\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd51f712",
   "metadata": {
    "papermill": {
     "duration": 0.042686,
     "end_time": "2022-05-29T15:55:15.314750",
     "exception": false,
     "start_time": "2022-05-29T15:55:15.272064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Word2Vec Embedding with FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b25350a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:55:15.401443Z",
     "iopub.status.busy": "2022-05-29T15:55:15.401218Z",
     "iopub.status.idle": "2022-05-29T15:56:20.533826Z",
     "shell.execute_reply": "2022-05-29T15:56:20.533092Z"
    },
    "papermill": {
     "duration": 65.220574,
     "end_time": "2022-05-29T15:56:20.578356",
     "exception": false,
     "start_time": "2022-05-29T15:55:15.357782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText Loaded!\n"
     ]
    }
   ],
   "source": [
    "fastText_model = KeyedVectors.load_word2vec_format('../input/wiki-vi-vectors/wiki.vi.vec')\n",
    "print(\"FastText Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "171444b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:56:20.667599Z",
     "iopub.status.busy": "2022-05-29T15:56:20.667344Z",
     "iopub.status.idle": "2022-05-29T15:56:20.688477Z",
     "shell.execute_reply": "2022-05-29T15:56:20.687239Z"
    },
    "papermill": {
     "duration": 0.067848,
     "end_time": "2022-05-29T15:56:20.690627",
     "exception": false,
     "start_time": "2022-05-29T15:56:20.622779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3644, 300)\n"
     ]
    }
   ],
   "source": [
    "embeddings_dim = 300\n",
    "\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, embeddings_dim))\n",
    "\n",
    "for word, index in word2idx.items():\n",
    "    try:\n",
    "        embedding_matrix[index,:] = fastText_model[word]\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df5ba2",
   "metadata": {
    "papermill": {
     "duration": 0.043313,
     "end_time": "2022-05-29T15:56:20.778037",
     "exception": false,
     "start_time": "2022-05-29T15:56:20.734724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model Defination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5012da88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:56:20.865143Z",
     "iopub.status.busy": "2022-05-29T15:56:20.864938Z",
     "iopub.status.idle": "2022-05-29T15:56:20.895396Z",
     "shell.execute_reply": "2022-05-29T15:56:20.894754Z"
    },
    "papermill": {
     "duration": 0.076126,
     "end_time": "2022-05-29T15:56:20.897136",
     "exception": false,
     "start_time": "2022-05-29T15:56:20.821010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Embedding Layer\n",
    "embedding_layer_question = Embedding(VOCAB_SIZE,embeddings_dim\n",
    "                                     ,input_length=maxlen_questions\n",
    "                                     ,weights = [embedding_matrix]\n",
    "                                     ,trainable=False)\n",
    "\n",
    "embedding_layer_answer = Embedding(VOCAB_SIZE,embeddings_dim\n",
    "                                     ,input_length=maxlen_answers\n",
    "                                     ,weights = [embedding_matrix]\n",
    "                                     ,trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1066c06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:56:20.986062Z",
     "iopub.status.busy": "2022-05-29T15:56:20.985854Z",
     "iopub.status.idle": "2022-05-29T15:56:24.032065Z",
     "shell.execute_reply": "2022-05-29T15:56:24.031213Z"
    },
    "id": "FsoW9mPPRSSk",
    "outputId": "536bdc53-d864-4933-dfd3-13a47d66d4ee",
    "papermill": {
     "duration": 3.09229,
     "end_time": "2022-05-29T15:56:24.034004",
     "exception": false,
     "start_time": "2022-05-29T15:56:20.941714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 15:56:21.058511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:21.151023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:21.151801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:21.152905: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-29 15:56:21.153222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:21.154052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:21.154840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:23.005145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:23.006063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:23.006774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 15:56:23.008196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 76)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 43)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 76, 300)      1093200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 43, 300)      1093200     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 43, 300), (N 721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 43, 3644)     1096844     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,725,644\n",
      "Trainable params: 2,539,244\n",
      "Non-trainable params: 2,186,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "encoder_inputs = Input(shape = (maxlen_questions, ))\n",
    "encoder_embedding = embedding_layer_question(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c = LSTM(300,dropout=0.05,return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(maxlen_answers, ))\n",
    "decoder_embedding = embedding_layer_answer(decoder_inputs)\n",
    "decoder_lstm = LSTM(300, return_state=True, return_sequences=True,dropout=0.05)\n",
    "decoder_outputs , _ , _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(VOCAB_SIZE, activation='softmax') \n",
    "output = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be272334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T15:56:24.124154Z",
     "iopub.status.busy": "2022-05-29T15:56:24.123631Z",
     "iopub.status.idle": "2022-05-29T16:12:55.217938Z",
     "shell.execute_reply": "2022-05-29T16:12:55.217038Z"
    },
    "id": "TvpmndMTDwU0",
    "papermill": {
     "duration": 991.141774,
     "end_time": "2022-05-29T16:12:55.220251",
     "exception": false,
     "start_time": "2022-05-29T15:56:24.078477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 15:56:24.129705: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3697931200 exceeds 10% of free system memory.\n",
      "2022-05-29 15:56:27.841675: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3697931200 exceeds 10% of free system memory.\n",
      "2022-05-29 15:56:30.513554: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 15:56:34.129562: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 9s 49ms/step - loss: 1.2558 - acc: 0.9108\n",
      "Epoch 2/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.4847 - acc: 0.9360\n",
      "Epoch 3/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4716 - acc: 0.9363\n",
      "Epoch 4/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.4642 - acc: 0.9363\n",
      "Epoch 5/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4585 - acc: 0.9364\n",
      "Epoch 6/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4527 - acc: 0.9363\n",
      "Epoch 7/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.4472 - acc: 0.9363\n",
      "Epoch 8/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.4415 - acc: 0.9365\n",
      "Epoch 9/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.4358 - acc: 0.9365\n",
      "Epoch 10/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4303 - acc: 0.9368\n",
      "Epoch 11/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.4253 - acc: 0.9371\n",
      "Epoch 12/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4201 - acc: 0.9372\n",
      "Epoch 13/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4151 - acc: 0.9373\n",
      "Epoch 14/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.4098 - acc: 0.9376\n",
      "Epoch 15/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4048 - acc: 0.9377\n",
      "Epoch 16/200\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.4012 - acc: 0.9377\n",
      "Epoch 17/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3946 - acc: 0.9380\n",
      "Epoch 18/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.3891 - acc: 0.9382\n",
      "Epoch 19/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3840 - acc: 0.9383\n",
      "Epoch 20/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3786 - acc: 0.9385\n",
      "Epoch 21/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.3737 - acc: 0.9387\n",
      "Epoch 22/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3690 - acc: 0.9390\n",
      "Epoch 23/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.3641 - acc: 0.9390\n",
      "Epoch 24/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.3590 - acc: 0.9393\n",
      "Epoch 25/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.3540 - acc: 0.9397\n",
      "Epoch 26/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3494 - acc: 0.9400\n",
      "Epoch 27/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3445 - acc: 0.9402\n",
      "Epoch 28/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.3399 - acc: 0.9406\n",
      "Epoch 29/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3353 - acc: 0.9408\n",
      "Epoch 30/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.3312 - acc: 0.9412\n",
      "Epoch 31/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.3265 - acc: 0.9416\n",
      "Epoch 32/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.3222 - acc: 0.9422\n",
      "Epoch 33/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3182 - acc: 0.9428\n",
      "Epoch 34/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3141 - acc: 0.9434\n",
      "Epoch 35/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.3100 - acc: 0.9438\n",
      "Epoch 36/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3070 - acc: 0.9443\n",
      "Epoch 37/200\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.3032 - acc: 0.9450\n",
      "Epoch 38/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2992 - acc: 0.9457\n",
      "Epoch 39/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2958 - acc: 0.9460\n",
      "Epoch 40/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2930 - acc: 0.9465\n",
      "Epoch 41/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2899 - acc: 0.9469\n",
      "Epoch 42/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2868 - acc: 0.9473\n",
      "Epoch 43/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2834 - acc: 0.9481\n",
      "Epoch 44/200\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.2804 - acc: 0.9484\n",
      "Epoch 45/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2777 - acc: 0.9487\n",
      "Epoch 46/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2749 - acc: 0.9492\n",
      "Epoch 47/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2719 - acc: 0.9497\n",
      "Epoch 48/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2692 - acc: 0.9502\n",
      "Epoch 49/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2664 - acc: 0.9507\n",
      "Epoch 50/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2638 - acc: 0.9513\n",
      "Epoch 51/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.2619 - acc: 0.9514\n",
      "Epoch 52/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.2590 - acc: 0.9519\n",
      "Epoch 53/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2567 - acc: 0.9524\n",
      "Epoch 54/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2541 - acc: 0.9527\n",
      "Epoch 55/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2519 - acc: 0.9530\n",
      "Epoch 56/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2495 - acc: 0.9535\n",
      "Epoch 57/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2470 - acc: 0.9540\n",
      "Epoch 58/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.2442 - acc: 0.9544\n",
      "Epoch 59/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.2418 - acc: 0.9548\n",
      "Epoch 60/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2398 - acc: 0.9552\n",
      "Epoch 61/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2378 - acc: 0.9555\n",
      "Epoch 62/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2351 - acc: 0.9560\n",
      "Epoch 63/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2333 - acc: 0.9561\n",
      "Epoch 64/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2316 - acc: 0.9565\n",
      "Epoch 65/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.2320 - acc: 0.9568\n",
      "Epoch 66/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.2275 - acc: 0.9575\n",
      "Epoch 67/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2255 - acc: 0.9578\n",
      "Epoch 68/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2231 - acc: 0.9582\n",
      "Epoch 69/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2207 - acc: 0.9587\n",
      "Epoch 70/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2192 - acc: 0.9589\n",
      "Epoch 71/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2169 - acc: 0.9594\n",
      "Epoch 72/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2149 - acc: 0.9597\n",
      "Epoch 73/200\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.2128 - acc: 0.9602\n",
      "Epoch 74/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2112 - acc: 0.9604\n",
      "Epoch 75/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2102 - acc: 0.9605\n",
      "Epoch 76/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2090 - acc: 0.9609\n",
      "Epoch 77/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2067 - acc: 0.9613\n",
      "Epoch 78/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2042 - acc: 0.9614\n",
      "Epoch 79/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2027 - acc: 0.9618\n",
      "Epoch 80/200\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.2006 - acc: 0.9621\n",
      "Epoch 81/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1992 - acc: 0.9621\n",
      "Epoch 82/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1975 - acc: 0.9625\n",
      "Epoch 83/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1961 - acc: 0.9627\n",
      "Epoch 84/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1942 - acc: 0.9632\n",
      "Epoch 85/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1930 - acc: 0.9633\n",
      "Epoch 86/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.1922 - acc: 0.9634\n",
      "Epoch 87/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.1904 - acc: 0.9635\n",
      "Epoch 88/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.1897 - acc: 0.9638\n",
      "Epoch 89/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1883 - acc: 0.9639\n",
      "Epoch 90/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2138 - acc: 0.9608\n",
      "Epoch 91/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2176 - acc: 0.9600\n",
      "Epoch 92/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2086 - acc: 0.9612\n",
      "Epoch 93/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2015 - acc: 0.9619\n",
      "Epoch 94/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.1967 - acc: 0.9627\n",
      "Epoch 95/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.1936 - acc: 0.9629\n",
      "Epoch 96/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1919 - acc: 0.9632\n",
      "Epoch 97/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1897 - acc: 0.9636\n",
      "Epoch 98/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1873 - acc: 0.9641\n",
      "Epoch 99/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1859 - acc: 0.9640\n",
      "Epoch 100/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.1849 - acc: 0.9642\n",
      "Epoch 101/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1829 - acc: 0.9646\n",
      "Epoch 102/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.1941 - acc: 0.9630\n",
      "Epoch 103/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1907 - acc: 0.9634\n",
      "Epoch 104/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1870 - acc: 0.9639\n",
      "Epoch 105/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1834 - acc: 0.9644\n",
      "Epoch 106/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.1814 - acc: 0.9645\n",
      "Epoch 107/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.1797 - acc: 0.9648\n",
      "Epoch 108/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2148 - acc: 0.9591\n",
      "Epoch 109/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.2648 - acc: 0.9499\n",
      "Epoch 110/200\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.2344 - acc: 0.9562\n",
      "Epoch 111/200\n",
      "93/93 [==============================] - 5s 48ms/step - loss: 0.2259 - acc: 0.9583\n",
      "Epoch 112/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2215 - acc: 0.9598\n",
      "Epoch 113/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2195 - acc: 0.9601\n",
      "Epoch 114/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.2177 - acc: 0.9607\n",
      "Epoch 115/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2165 - acc: 0.9608\n",
      "Epoch 116/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2153 - acc: 0.9611\n",
      "Epoch 117/200\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.2145 - acc: 0.9612\n",
      "Epoch 118/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2138 - acc: 0.9614\n",
      "Epoch 119/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2132 - acc: 0.9614\n",
      "Epoch 120/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2126 - acc: 0.9617\n",
      "Epoch 121/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.2120 - acc: 0.9616\n",
      "Epoch 122/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2115 - acc: 0.9616\n",
      "Epoch 123/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2111 - acc: 0.9617\n",
      "Epoch 124/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2110 - acc: 0.9616\n",
      "Epoch 125/200\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.2105 - acc: 0.9617\n",
      "Epoch 126/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2101 - acc: 0.9618\n",
      "Epoch 127/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2099 - acc: 0.9619\n",
      "Epoch 128/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2097 - acc: 0.9618\n",
      "Epoch 129/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2095 - acc: 0.9618\n",
      "Epoch 130/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2091 - acc: 0.9620\n",
      "Epoch 131/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2089 - acc: 0.9618\n",
      "Epoch 132/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2086 - acc: 0.9619\n",
      "Epoch 133/200\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.2085 - acc: 0.9619\n",
      "Epoch 134/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2082 - acc: 0.9619\n",
      "Epoch 135/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2081 - acc: 0.9619\n",
      "Epoch 136/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2079 - acc: 0.9619\n",
      "Epoch 137/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2078 - acc: 0.9619\n",
      "Epoch 138/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2077 - acc: 0.9619\n",
      "Epoch 139/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2077 - acc: 0.9617\n",
      "Epoch 140/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2073 - acc: 0.9619\n",
      "Epoch 141/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2071 - acc: 0.9619\n",
      "Epoch 142/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.2071 - acc: 0.9619\n",
      "Epoch 143/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2069 - acc: 0.9620\n",
      "Epoch 144/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2069 - acc: 0.9619\n",
      "Epoch 145/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2066 - acc: 0.9617\n",
      "Epoch 146/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2064 - acc: 0.9619\n",
      "Epoch 147/200\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.2063 - acc: 0.9618\n",
      "Epoch 148/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.2062 - acc: 0.9621\n",
      "Epoch 149/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.2061 - acc: 0.9620\n",
      "Epoch 150/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2060 - acc: 0.9619\n",
      "Epoch 151/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.2059 - acc: 0.9619\n",
      "Epoch 152/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2058 - acc: 0.9620\n",
      "Epoch 153/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.2053 - acc: 0.9622\n",
      "Epoch 154/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2050 - acc: 0.9620\n",
      "Epoch 155/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.2035 - acc: 0.9622\n",
      "Epoch 156/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.2005 - acc: 0.9623\n",
      "Epoch 157/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1966 - acc: 0.9628\n",
      "Epoch 158/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1945 - acc: 0.9632\n",
      "Epoch 159/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1917 - acc: 0.9632\n",
      "Epoch 160/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1903 - acc: 0.9637\n",
      "Epoch 161/200\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.1885 - acc: 0.9639\n",
      "Epoch 162/200\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 0.1868 - acc: 0.9641\n",
      "Epoch 163/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1841 - acc: 0.9645\n",
      "Epoch 164/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1813 - acc: 0.9645\n",
      "Epoch 165/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1791 - acc: 0.9649\n",
      "Epoch 166/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1753 - acc: 0.9653\n",
      "Epoch 167/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1732 - acc: 0.9654\n",
      "Epoch 168/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1710 - acc: 0.9659\n",
      "Epoch 169/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.1703 - acc: 0.9659\n",
      "Epoch 170/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1685 - acc: 0.9662\n",
      "Epoch 171/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1673 - acc: 0.9661\n",
      "Epoch 172/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1668 - acc: 0.9663\n",
      "Epoch 173/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1645 - acc: 0.9667\n",
      "Epoch 174/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1637 - acc: 0.9668\n",
      "Epoch 175/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.1623 - acc: 0.9669\n",
      "Epoch 176/200\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1612 - acc: 0.9670\n",
      "Epoch 177/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.1598 - acc: 0.9673\n",
      "Epoch 178/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1589 - acc: 0.9674\n",
      "Epoch 179/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1574 - acc: 0.9676\n",
      "Epoch 180/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1569 - acc: 0.9677\n",
      "Epoch 181/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1549 - acc: 0.9682\n",
      "Epoch 182/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1545 - acc: 0.9680\n",
      "Epoch 183/200\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.1528 - acc: 0.9683\n",
      "Epoch 184/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1526 - acc: 0.9684\n",
      "Epoch 185/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1512 - acc: 0.9686\n",
      "Epoch 186/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1502 - acc: 0.9687\n",
      "Epoch 187/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1495 - acc: 0.9689\n",
      "Epoch 188/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1486 - acc: 0.9689\n",
      "Epoch 189/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1478 - acc: 0.9690\n",
      "Epoch 190/200\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.1458 - acc: 0.9693\n",
      "Epoch 191/200\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.1455 - acc: 0.9694\n",
      "Epoch 192/200\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.1448 - acc: 0.9695\n",
      "Epoch 193/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1430 - acc: 0.9697\n",
      "Epoch 194/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1427 - acc: 0.9697\n",
      "Epoch 195/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1415 - acc: 0.9699\n",
      "Epoch 196/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1412 - acc: 0.9701\n",
      "Epoch 197/200\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.1397 - acc: 0.9702\n",
      "Epoch 198/200\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.1388 - acc: 0.9702\n",
      "Epoch 199/200\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.1381 - acc: 0.9703\n",
      "Epoch 200/200\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.1374 - acc: 0.9706\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model.h5', monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "# train model\n",
    "history = model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=64, epochs=200) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ba69c9",
   "metadata": {
    "papermill": {
     "duration": 4.61646,
     "end_time": "2022-05-29T16:13:04.160916",
     "exception": false,
     "start_time": "2022-05-29T16:12:59.544456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Visualize Training Progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8e060d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T16:13:13.048452Z",
     "iopub.status.busy": "2022-05-29T16:13:13.048179Z",
     "iopub.status.idle": "2022-05-29T16:13:13.278938Z",
     "shell.execute_reply": "2022-05-29T16:13:13.278253Z"
    },
    "papermill": {
     "duration": 4.842998,
     "end_time": "2022-05-29T16:13:13.280665",
     "exception": false,
     "start_time": "2022-05-29T16:13:08.437667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "# Plot training accuracy & loss values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Accuracy','Loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34e1a1ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T16:13:22.422363Z",
     "iopub.status.busy": "2022-05-29T16:13:22.422029Z",
     "iopub.status.idle": "2022-05-29T16:13:22.476549Z",
     "shell.execute_reply": "2022-05-29T16:13:22.475810Z"
    },
    "papermill": {
     "duration": 4.688325,
     "end_time": "2022-05-29T16:13:22.478950",
     "exception": false,
     "start_time": "2022-05-29T16:13:17.790625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights('chatbot_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b46350",
   "metadata": {
    "papermill": {
     "duration": 4.319983,
     "end_time": "2022-05-29T16:13:31.348698",
     "exception": false,
     "start_time": "2022-05-29T16:13:27.028715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Defining Inference Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ef85d50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T16:13:40.466898Z",
     "iopub.status.busy": "2022-05-29T16:13:40.466569Z",
     "iopub.status.idle": "2022-05-29T16:13:40.472825Z",
     "shell.execute_reply": "2022-05-29T16:13:40.472112Z"
    },
    "id": "7mIQvGDZTcHq",
    "papermill": {
     "duration": 4.362139,
     "end_time": "2022-05-29T16:13:40.474603",
     "exception": false,
     "start_time": "2022-05-29T16:13:36.112464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = Input(shape=(300,))\n",
    "    decoder_state_input_c = Input(shape=(300,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    \n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac05552",
   "metadata": {
    "papermill": {
     "duration": 4.458978,
     "end_time": "2022-05-29T16:13:49.382924",
     "exception": false,
     "start_time": "2022-05-29T16:13:44.923946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Bot Chatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d173a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T16:13:58.803301Z",
     "iopub.status.busy": "2022-05-29T16:13:58.802946Z",
     "iopub.status.idle": "2022-05-29T16:13:58.808075Z",
     "shell.execute_reply": "2022-05-29T16:13:58.807358Z"
    },
    "id": "EaVIb-nYTenp",
    "papermill": {
     "duration": 4.59269,
     "end_time": "2022-05-29T16:13:58.809918",
     "exception": false,
     "start_time": "2022-05-29T16:13:54.217228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def str_to_tokens(sentence):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    tokens_list = []\n",
    "    \n",
    "    for word in words:\n",
    "        tokens_list.append(tokenizer.word_index[word]) \n",
    "    return pad_sequences([tokens_list],maxlen = maxlen_questions , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10d0b0f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T16:14:07.723165Z",
     "iopub.status.busy": "2022-05-29T16:14:07.722912Z",
     "iopub.status.idle": "2022-05-29T16:14:08.234971Z",
     "shell.execute_reply": "2022-05-29T16:14:08.233599Z"
    },
    "id": "mjaicXTBUBC7",
    "papermill": {
     "duration": 5.075283,
     "end_time": "2022-05-29T16:14:08.236490",
     "exception": true,
     "start_time": "2022-05-29T16:14:03.161207",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: Xin chào! Tôi là ChatBot. Nếu bạn muốn ngưng cuộc trò chuyện, hãy gõ Bye!\n"
     ]
    },
    {
     "ename": "StdinNotImplementedError",
     "evalue": "raw_input was called, but this frontend does not support input requests.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17/1112846999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhuman_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter question : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhuman_response\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_stdin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             raise StdinNotImplementedError(\n\u001b[0;32m-> 1074\u001b[0;31m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m             )\n\u001b[1;32m   1076\u001b[0m         return self._input_request(\n",
      "\u001b[0;31mStdinNotImplementedError\u001b[0m: raw_input was called, but this frontend does not support input requests."
     ]
    }
   ],
   "source": [
    "enc_model ,dec_model = make_inference_models()\n",
    "\n",
    "flag=True\n",
    "print(\"BOT: Xin chào! Tôi là ChatBot. Nếu bạn muốn ngưng cuộc trò chuyện, hãy gõ Bye!\")\n",
    "\n",
    "while(flag==True):\n",
    "    human_response = input('Enter question : ')\n",
    "    if human_response != 'bye':\n",
    "        try:\n",
    "            states_values = enc_model.predict(str_to_tokens(human_response))\n",
    "            empty_target_seq = np.zeros((1, 1))\n",
    "            empty_target_seq[0, 0] = word2idx['start']\n",
    "            stop_condition = False\n",
    "            decoded_translation = ''\n",
    "            while not stop_condition:\n",
    "                dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
    "\n",
    "                sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "                sampled_word = None\n",
    "                for word, index in word2idx.items() :\n",
    "                    if sampled_word_index == index:\n",
    "                        decoded_translation += ' {}'.format(word)\n",
    "                        sampled_word = word\n",
    "\n",
    "                if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "                    stop_condition = True\n",
    "\n",
    "                empty_target_seq = np.zeros((1, 1))  \n",
    "                empty_target_seq[0 , 0] = sampled_word_index\n",
    "                states_values = [h, c] \n",
    "\n",
    "            print('BOT: ' + decoded_translation.replace(\"end\",\"\"))\n",
    "        except:\n",
    "            print(\"BOT: Xin lỗi câu này tôi chưa đc học ,vui lòng hỏi lại :( \")\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"BOT: Tạm biệt nha!\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1175.946516,
   "end_time": "2022-05-29T16:14:15.590700",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-29T15:54:39.644184",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
